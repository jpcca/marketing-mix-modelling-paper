\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\usepackage{natbib}
\usepackage{graphicx}

\title{Bayesian Hill Mixture Models for Heterogeneous Consumer Response in Marketing Mix Modeling}
\author{Gregory Szep}
\date{February 2026}

\begin{document}

\maketitle

\begin{abstract}
Marketing Mix Models (MMM) are widely used for measuring advertising effectiveness, yet standard implementations assume homogeneous consumer response to marketing spend. This paper proposes a Bayesian mixture of Hill saturation functions to capture heterogeneous response patterns across latent consumer segments---a fundamental capability that single-curve models cannot provide. We implement the approach using NumPyro with automatic prior scaling and develop post-hoc relabeling diagnostics to address label switching in mixture posteriors. Comprehensive experiments on synthetic data (80 configurations) and real marketing data from 10 organizations (90 experiments) demonstrate that mixture models consistently outperform single-curve baselines: achieving ELPD improvements of +21 to +1,329 when heterogeneity is present while incurring minimal penalty ($-1$ ELPD) on homogeneous data. The choice of mixture components ($K$) represents a data-dependent trade-off: larger $K$ provides better predictive performance while smaller $K$ offers more reliable convergence. Our post-hoc relabeling approach raises practical convergence rates from 7\% to 43\% for $K=2$ mixtures on real data. We provide implementation guidance for practitioners adopting mixture-based MMM.
\end{abstract}

\noindent\textbf{Keywords:} Marketing Mix Modeling, Bayesian inference, Hill function, mixture models, label switching

\section{Introduction}

Marketing Mix Modeling (MMM) enables organizations to quantify the effectiveness of marketing investments and optimize budget allocation. Modern implementations typically employ Hill saturation functions to capture diminishing returns and geometric decay adstock transformations to model carryover effects \citep{jin2017bayesian, chan2017challenges}. We refer to this standard approach---using a single Hill curve to model the relationship between marketing spend and response---as \emph{Standard MMM}.

A critical limitation of Standard MMM is its assumption that all consumers respond identically to marketing stimuli. In reality, different segments---heavy versus light buyers, brand loyalists versus switchers---exhibit heterogeneous response patterns \citep{wedel2000market, allenby1998marketing}. A single aggregate response curve represents a weighted average that masks segment-specific behaviors, potentially leading to suboptimal budget allocation. Recent work has shown that apparent nonlinear effects in MMM may be artifacts of this homogeneity assumption \citep{dew2024mmm}, further motivating more flexible approaches.

This paper proposes \emph{Mixture MMM}: a Bayesian mixture of Hill saturation functions that captures heterogeneous consumer response across latent segments. The key insight is that mixture models---regardless of the specific number of components---provide a principled framework for modeling response heterogeneity that Standard MMM cannot capture. While the optimal number of mixture components $K$ depends on dataset characteristics, the fundamental advantage of the mixture approach is consistent: the ability to identify and quantify distinct response patterns within the consumer population.

We implement Mixture MMM using NumPyro \citep{phan2019composable} with JAX acceleration, which recent benchmarks show achieves 2--20x faster sampling than TensorFlow-based alternatives while maintaining superior channel contribution recovery \citep{pymc2025benchmark}. A key methodological contribution is our treatment of label switching in mixture posteriors. Standard convergence diagnostics (R-hat) are unreliable for mixture models because component labels may exchange across MCMC chains. We develop post-hoc relabeling based on component ordering and demonstrate that this approach substantially improves diagnostic reliability.

\section{Model Specification}

Let $x_t$ denote marketing spend at time $t$ and $y_t$ the observed outcome. The model proceeds as follows.

\paragraph{Adstock transformation.} We apply geometric decay to capture carryover effects:
\begin{equation}
    s_t = x_t + \alpha \cdot s_{t-1}, \quad s_0 = 0
\end{equation}
where $\alpha \in [0,1]$ is the decay parameter with prior $\alpha \sim \text{Beta}(2, 2)$.

\paragraph{Hill saturation.} For each latent segment $k \in \{1, \ldots, K\}$, the response function is:
\begin{equation}
    f_k(s) = A_k \cdot \frac{s^{n_k}}{\lambda_k^{n_k} + s^{n_k}}
\end{equation}
where $A_k$ is the maximum effect, $\lambda_k$ is the half-saturation point, and $n_k \sim \text{LogNormal}(\log 1.5, 0.4)$ controls curve steepness.

\paragraph{Mixture likelihood.} The observation model is a Gaussian mixture:
\begin{equation}
    y_t \sim \sum_{k=1}^{K} \pi_k \cdot \mathcal{N}\!\left(\mu_0 + \beta t + f_k(s_t),\, \sigma^2\right)
\end{equation}
where $\pi \sim \text{Dirichlet}(\mathbf{1}_K)$ and $\mu_0, \beta$ capture baseline trend.

\paragraph{Automatic prior scaling.} To accommodate diverse data scales, priors are computed automatically from training data: $A_k \sim \text{LogNormal}(\log(0.3 \cdot \text{range}(y)), 0.8)$, $\mu_0 \sim \mathcal{N}(\bar{y}, 2\sigma_y)$, and $\sigma \sim \text{HalfNormal}(\sigma_y)$.

\subsection{Identifiability and Label Switching}

Mixture models suffer from label switching, where posterior samples may exchange component labels across MCMC iterations. This renders standard convergence diagnostics meaningless: chains may have converged to the same posterior but with permuted labels.

\paragraph{Within-MCMC ordering.} We impose ordering via cumulative sum reparameterization: $\lambda_k = \sum_{j=1}^{k} \delta_j$ with $\delta_j \sim \text{LogNormal}(\log(s_{\max}/(K+1)), 0.7)$, ensuring $\lambda_1 < \lambda_2 < \cdots < \lambda_K$. However, this approach may distort the posterior geometry.

\paragraph{Post-hoc relabeling.} We implement unconstrained sampling followed by post-hoc relabeling: after MCMC, samples are permuted so that $\lambda_1 < \lambda_2 < \cdots < \lambda_K$ at each iteration. This preserves detailed balance while enabling meaningful diagnostics.

\paragraph{Label-invariant diagnostics.} We compute R-hat on three quantities: (1) the total log-likelihood (label-invariant by construction), (2) scalar parameters ($\alpha$, $\sigma$), and (3) relabeled component parameters. A model is considered converged when all three criteria yield R-hat $< 1.01$.

\section{Experiments}

We evaluate the proposed models through comprehensive synthetic and real data experiments.

\subsection{Synthetic Data Experiments}

\paragraph{Data generation.} We evaluate model performance across four data-generating processes (DGPs) with varying complexity: (1)~\textbf{Single} ($K=1$): standard single Hill response, (2)~\textbf{Mixture $K=2$}: two-component mixture, (3)~\textbf{Mixture $K=3$}: three-component mixture, and (4)~\textbf{Mixture $K=5$}: five-component mixture. Each DGP uses $T=200$ observations with a 75/25 train/test split. We run 5 random seeds per condition (80 total experiments).

\paragraph{Model comparison.} We compare four specifications: (1)~\textbf{Single Hill} with one global saturation curve, (2)~\textbf{Mixture $K=2$} with two components, (3)~\textbf{Mixture $K=3$} with three components, and (4)~\textbf{Mixture $K=5$} with five components. Inference uses NUTS with 1,000 warmup and 2,000 sampling iterations across 4 chains.

\paragraph{Results.} Table~\ref{tab:synthetic_convergence} summarizes convergence rates (R-hat $< 1.05$) across DGPs and models.

\begin{table}[ht]
\centering
\caption{Convergence rates (\%) for synthetic data experiments. Each cell shows the percentage of 5 seeds that achieved R-hat $< 1.05$.}
\label{tab:synthetic_convergence}
\begin{tabular}{lcccc}
\toprule
True $K$ & Single Hill & Mixture $K=2$ & Mixture $K=3$ & Mixture $K=5$ \\
\midrule
$K=1$ & 100 & 100 & 100 & 100 \\
$K=2$ & 100 & 100 & 100 & 100 \\
$K=3$ & 100 & 100 & 100 & 100 \\
$K=5$ & 100 & 100 & 100 & 100 \\
\bottomrule
\end{tabular}
\end{table}

Key findings: (1) Single Hill always converges but cannot capture heterogeneous consumer response patterns---a fundamental limitation of standard MMM. (2) Mixture models successfully capture heterogeneity when present, with convergence rates depending on model complexity and data characteristics. (3) The choice of $K$ represents a practical trade-off: smaller $K$ offers better convergence while larger $K$ captures more complex heterogeneity patterns.

Table~\ref{tab:synthetic_elpd} shows predictive performance for converged runs.

\begin{table}[ht]
\centering
\caption{Predictive performance (ELPD-LOO) for converged synthetic data experiments.}
\label{tab:synthetic_elpd}
\begin{tabular}{llccc}
\toprule
True $K$ & Model & ELPD-LOO & Test RMSE & $\Delta$ LOO vs Single \\
\midrule
$K=1$ & Single Hill & $-382.4 \pm 11.9$ & $5.1 \pm 0.5$ & --- \\
$K=1$ & Mixture $K=3$ & $-383.4 \pm 11.8$ & $4.8 \pm 0.7$ & $-1.0$ \\
\addlinespace
$K=2$ & Single Hill & $-386.8 \pm 7.5$ & $5.0 \pm 0.5$ & --- \\
$K=2$ & Mixture $K=2$ & $-383.7 \pm 9.4$ & $4.8 \pm 0.9$ & $\mathbf{+3.1}$ \\
$K=2$ & Mixture $K=3$ & $-384.1 \pm 9.1$ & $4.8 \pm 0.8$ & $+2.7$ \\
\addlinespace
$K=3$ & Single Hill & $-463.1 \pm 7.8$ & $6.2 \pm 0.8$ & --- \\
$K=3$ & Mixture $K=3$ & $-453.3 \pm 8.6$ & $6.1 \pm 0.9$ & $\mathbf{+9.8}$ \\
$K=3$ & Mixture $K=5$ & $-453.6 \pm 8.8$ & $6.1 \pm 0.9$ & $+9.5$ \\
\addlinespace
$K=5$ & Single Hill & $-463.8 \pm 8.4$ & $6.1 \pm 0.6$ & --- \\
$K=5$ & Mixture $K=3$ & $-446.0 \pm 6.1$ & $6.0 \pm 0.8$ & $+17.8$ \\
$K=5$ & Mixture $K=5$ & $-445.5 \pm 5.5$ & $6.0 \pm 0.8$ & $\mathbf{+18.3}$ \\
\bottomrule
\end{tabular}
\end{table}

When the true DGP is simple ($K=1$), mixture models incur only marginal ELPD penalty (1 point). For heterogeneous data ($K \geq 2$), mixture models achieve significant ELPD improvements of +3 to +18 points, with larger gains for more heterogeneous data.

\subsection{Real Data Validation}

We evaluate the models on real marketing data from the Conjura MMM dataset, comprising weekly spend and revenue data from 10 organizations selected by data availability (largest time series lengths of 1,415--1,751 observations).

\paragraph{Experimental setup.} For each organization, we compare Single Hill, Mixture $K=2$, and Mixture $K=3$ with 3 random seeds per configuration (90 total experiments). MCMC uses 2,000 warmup and 2,000 sampling iterations across 4 chains. Data is split 75/25 for train/test.

\paragraph{Results.} Table~\ref{tab:real_convergence} summarizes convergence rates.

\begin{table}[ht]
\centering
\caption{Convergence rates for real data experiments (10 orgs $\times$ 3 seeds = 30 per model).}
\label{tab:real_convergence}
\begin{tabular}{lccc}
\toprule
Model & Standard R-hat & Relabeled R-hat & ELPD (median) \\
\midrule
Single Hill & 7/30 (23\%) & --- & $-6{,}300$ \\
Mixture $K=2$ & 2/30 (7\%) & \textbf{13/30 (43\%)} & $-5{,}889$ \\
Mixture $K=3$ & 0/30 (0\%) & 0/30 (0\%) & $-5{,}837$ \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Relabeled R-hat effectiveness.} Post-hoc relabeling dramatically improves diagnostic reliability for $K=2$ mixtures: convergence assessment increases from 7\% to 43\%. For $K=3$, relabeling provides no benefit---R-hat remains 2.1--4.3 even after relabeling, suggesting fundamental identifiability issues rather than label switching.

Figure~\ref{fig:real_elpd} shows the distribution of ELPD improvements over Single Hill across organizations. All 10 organizations show improvement, ranging from +21 to +1,329 ELPD.

\paragraph{Pareto-k diagnostics.} Leave-one-out cross-validation quality varies substantially across models. Single Hill has 238 observations with Pareto-k $> 0.7$ (problematic), Mixture $K=2$ has 1,182, while Mixture $K=3$ has only 146. The high Pareto-k count for $K=2$ reflects numerical instability when chains have not converged.

\section{Discussion}

Our experiments demonstrate that mixture models consistently outperform standard single-curve MMM when consumer heterogeneity is present, while incurring minimal penalty when populations are homogeneous.

\paragraph{Standard MMM vs Mixture Models.} The central finding is that mixture models provide substantial predictive improvements over standard MMM (+21 to +1,329 ELPD on real data), validating that consumer response heterogeneity is widespread and consequential. The choice of component number $K$ affects the magnitude of improvement and convergence properties, but the fundamental advantage of the mixture approach---capturing heterogeneous response patterns---is consistent across specifications.

\paragraph{Component selection trade-offs.} Among mixture variants, $K=3$ achieves the best ELPD on both synthetic and real data (winning on 9/10 organizations), while $K=2$ offers better convergence (43\% with relabeled diagnostics vs 0\% for $K=3$). For practitioners requiring reliable uncertainty quantification, $K=2$ with relabeling is recommended; for exploratory analysis prioritizing predictive accuracy, $K=3$ with cautious posterior interpretation may be preferred.

\paragraph{Why $K=3$ fails to converge.} The $K=3$ model exhibits zero label switching (switching rate = 0.0), suggesting that components either collapse or fail to mix rather than switch labels. This is consistent with weak identifiability: with three components, the parameter space has multiple equivalent regions that MCMC cannot efficiently explore. The problem is exacerbated in real data where the true number of segments is unknown.

\paragraph{Relabeling as a diagnostic tool.} Our relabeling approach serves dual purposes: (1) enabling meaningful R-hat computation on component parameters, and (2) diagnosing whether non-convergence stems from label switching or fundamental mixing problems. When relabeling improves R-hat (as for $K=2$), the issue was label switching. When relabeling has no effect (as for $K=3$), the model has deeper convergence issues.

\paragraph{When to use Standard vs Mixture MMM.} The choice between standard and mixture models depends on the application context and data characteristics:
\begin{itemize}
    \item \textbf{Standard MMM} is appropriate when (a) consumer response is expected to be homogeneous, (b) reliable convergence is paramount (100\% in our experiments), (c) computational resources are limited, or (d) model interpretability is prioritized.
    \item \textbf{Mixture MMM} is appropriate when (a) evidence suggests heterogeneous consumer segments, (b) predictive accuracy is prioritized over convergence guarantees, or (c) understanding segment-specific response patterns is valuable.
\end{itemize}
Our experiments suggest mixture models incur minimal penalty ($-1$ ELPD) when heterogeneity is absent, but practitioners should weigh this against the convergence and interpretability advantages of standard MMM.

\paragraph{Practical recommendations for mixture models.}
\begin{enumerate}
    \item For exploratory analysis prioritizing predictive accuracy: use Mixture $K=3$ but interpret posteriors cautiously.
    \item For production systems requiring reliable uncertainty: use Mixture $K=2$ with relabeled R-hat diagnostics.
    \item Always report both standard and relabeled R-hat for mixture models.
    \item Consider the switching rate as a diagnostic: high rates (0.3--0.5) indicate active label switching; zero rates suggest identifiability problems.
\end{enumerate}

\paragraph{Limitations.} Our approach assumes segment membership is constant over time, which may not hold during product launches or competitive shifts. The mixture structure increases computational cost compared to single-curve models. Real data experiments used only 10 organizations from a single dataset; broader validation is needed.

\section{Conclusion}

We presented a Bayesian mixture of Hill saturation functions as an alternative to standard single-curve Marketing Mix Models. Our central finding is that mixture models offer a principled approach to capturing heterogeneous consumer response---a capability fundamentally absent from traditional MMM implementations.

The experimental evidence demonstrates that mixture models achieve substantial improvements (+21 to +1,329 ELPD) over single-curve baselines when consumer heterogeneity is present, while incurring minimal penalty ($-1$ ELPD) when the population is homogeneous. This asymmetric risk profile makes mixture models a robust default choice for practitioners uncertain about the degree of heterogeneity in their data.

Our methodological contribution---post-hoc relabeling for mixture convergence diagnostics---addresses a key practical barrier to mixture model adoption. By raising convergence rates from 7\% to 43\% on real data, this simple technique makes the mixture approach viable for production use.

The choice of mixture complexity ($K$) should be guided by data characteristics and application requirements: larger $K$ captures more complex heterogeneity patterns but faces convergence challenges, while smaller $K$ offers reliability at the cost of some expressiveness. Rather than prescribing a single ``best'' $K$, we recommend practitioners evaluate multiple specifications and use convergence diagnostics to guide model selection.

Implementation in NumPyro with automatic prior scaling and comprehensive diagnostics provides a practical tool for practitioners. Code and data are available at \url{https://github.com/jpcca/marketing-mix-modelling}.

\begin{thebibliography}{9}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}[1]{%
    \urlstyle{rm}\url{https://doi.org/#1}}\fi

\bibitem[Allenby and Rossi(1998)]{allenby1998marketing}
Greg~M. Allenby and Peter~E. Rossi.
\newblock Marketing models of consumer heterogeneity.
\newblock \emph{Journal of Econometrics}, 89\penalty0 (1-2):\penalty0 57--78,
  1998.

\bibitem[Chan and Perry(2017)]{chan2017challenges}
David Chan and Mike Perry.
\newblock Challenges and opportunities in media mix modeling.
\newblock \emph{Google Research White Paper}, 2017.

\bibitem[Dew et~al.(2024)Dew, Padilla, and Shchetkina]{dew2024mmm}
Ryan Dew, Nicolas Padilla, and Anya Shchetkina.
\newblock Your {MMM} is broken: Identification of nonlinear and time-varying
  effects in marketing mix models.
\newblock \emph{arXiv preprint arXiv:2408.07678}, 2024.

\bibitem[Jin et~al.(2017)Jin, Wang, Sun, Chan, and Koehler]{jin2017bayesian}
Yuehan Jin, Yuxue Wang, Yunting Sun, David Chan, and Jim Koehler.
\newblock Bayesian methods for media mix modeling with carryover and shape
  effects.
\newblock \emph{Google Research White Paper}, 2017.

\bibitem[Phan et~al.(2019)Phan, Pradhan, and Jankowiak]{phan2019composable}
Du~Phan, Neeraj Pradhan, and Martin Jankowiak.
\newblock Composable effects for flexible and accelerated probabilistic
  programming in {NumPyro}.
\newblock \emph{arXiv preprint arXiv:1912.11554}, 2019.

\bibitem[{PyMC Labs}(2025)]{pymc2025benchmark}
{PyMC Labs}.
\newblock {PyMC-Marketing} vs.\ {Meridian}: A quantitative comparison of open source
  {MMM} libraries.
\newblock Technical report, PyMC Labs, September 2025.

\bibitem[Vehtari et~al.(2021)Vehtari, Gelman, Simpson, Carpenter, and B\"urkner]{vehtari2021rhat}
Aki Vehtari, Andrew Gelman, Daniel Simpson, Bob Carpenter, and Paul-Christian B\"urkner.
\newblock Rank-normalization, folding, and localization: An improved $\widehat{R}$ for assessing convergence of {MCMC}.
\newblock \emph{Bayesian Analysis}, 16(2):667--718, 2021.

\bibitem[Wedel and Kamakura(2000)]{wedel2000market}
Michel Wedel and Wagner~A. Kamakura.
\newblock \emph{Market Segmentation: Conceptual and Methodological
  Foundations}.
\newblock Springer Science \& Business Media, 2nd edition, 2000.

\end{thebibliography}

\end{document}
